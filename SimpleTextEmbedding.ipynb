{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPOV68y+w5+Dw7mwMrJ9Lsf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/siddharthsharma22/pythoncodes/blob/main/SimpleTextEmbedding.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UO57xgqTr4YT",
        "outputId": "4eb01ef9-ffdb-478c-f1ea-5a05d91d4f4f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['word', 'embeddings', 'are', 'a', 'type', 'of', 'word', 'representation', 'that', 'allows', 'words', 'with', 'similar', 'meaning', 'to', 'have', 'a', 'similar', 'representation', '.']]\n",
            "[-0.01735336 -0.00290427  0.01895665 -0.01509456 -0.01074036  0.01862565\n",
            " -0.01793704  0.00765911  0.00131971  0.01330865  0.01664118 -0.00570303\n",
            " -0.00797794  0.01780579  0.00417286  0.01249927 -0.01888847  0.0191909\n",
            " -0.0027121  -0.01212793  0.00599713 -0.00090749  0.00942904 -0.00455045\n",
            " -0.00826924  0.00455398  0.01670576 -0.00997918  0.00532536 -0.01598125\n",
            " -0.01354646 -0.00093874 -0.01752879  0.00556919  0.00319417 -0.0046524\n",
            "  0.01001785  0.01949476  0.01690674 -0.0037733   0.0041074  -0.00800076\n",
            " -0.01649537  0.0125471  -0.00388685 -0.00132606 -0.00354332 -0.00907581\n",
            "  0.00812883 -0.00854134]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "from gensim.models import Word2Vec\n",
        "from nltk.tokenize import word_tokenize\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Sample text data\n",
        "text_data = \"Word embeddings are a type of word representation that allows words with similar meaning to have a similar representation.\"\n",
        "\n",
        "# Tokenize the text\n",
        "tokenized_data = [word_tokenize(text_data.lower())]\n",
        "print(tokenized_data)\n",
        "# Create the Word2Vec model\n",
        "model = Word2Vec(tokenized_data, min_count=1, vector_size=50, workers=3, window=3, sg=1)\n",
        "\n",
        "# Get the word vector for a specific word\n",
        "word_vector = model.wv['embeddings']\n",
        "\n",
        "# Print the word vector\n",
        "\n",
        "print(word_vector)"
      ]
    }
  ]
}